{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b789a-464a-4e0f-ac24-f9192eb9aca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストール\n",
    "# 一度やれば~/.local以下にインストールされるので再実行する必要はないです\n",
    "# \n",
    "# !pip install transformers accelerate langchain tiktoken sentence_transformers faiss-gpu boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb832c5a-ea5d-4701-bf32-07f97e41a154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d02746-ea73-4a6d-b356-712c8d03f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# オブジェクトストレージにアクセスするための設定\n",
    "# 使用するオブジェクトストレージに合わせて変更すること\n",
    "# キーをベタ書きしてるので良い子はまねしないでね\n",
    "\n",
    "accesskey = \"LpkzPlUyAwDO2CQHE0XnW307GdqSJtms\"\n",
    "secretkey = \"bUewoPAJnoKI2FhzJPYQnnFkLG-v382z\"\n",
    "endpoint = \"http://10.38.76.10\"\n",
    "bucket = \"langchain-bucket\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c88804-3695-4668-8f1a-b7802daa1e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# 事前に作成しておいたベクトルDBをオブジェクトストレージからロードする\n",
    "\n",
    "import boto3\n",
    "import pickle\n",
    "\n",
    "s3_client = boto3.client( \n",
    "    \"s3\",\n",
    "    aws_access_key_id=accesskey ,\n",
    "    aws_secret_access_key=secretkey,\n",
    "    endpoint_url=endpoint\n",
    ")\n",
    "\n",
    "response = s3_client.get_object(\n",
    "    Bucket=bucket, \n",
    "    Key=\"vectorstore.pkl\"\n",
    ")\n",
    "\n",
    "body = response['Body'].read()\n",
    "vectorstore = pickle.loads(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334b7cd-8b25-4a1f-a39b-76d130037ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# ベクトル検索\n",
    "\n",
    "import time\n",
    "\n",
    "question = \"Nutanixでイレイジャーコーディングが適しているのはどのような場合ですか？\"\n",
    "\n",
    "start = time.time()\n",
    "# 質問に対して、データベース中の類似度上位3件を抽出。質問の文章はこの関数でベクトル化され利用される\n",
    "docs = vectorstore.similarity_search(question, k=3)\n",
    "elapsed_time = time.time() - start\n",
    "print(f\"処理時間[s]: {elapsed_time:.2f}\")\n",
    "for i in range(len(docs)):\n",
    "    print(docs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01a6384-52bc-461c-8a25-a5e57e58e267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# LLMをロードする。\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "\n",
    "assert transformers.__version__ >= \"4.34.1\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"cyberagent/calm2-7b-chat\", device_map=\"auto\", torch_dtype=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cyberagent/calm2-7b-chat\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b37cd-54b4-4ae5-8dad-f799842e4cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#################################################################\n",
    "# RAG のためのLangChainのインタフェース準備\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=150,\n",
    "    do_sample=True,\n",
    "    temperature=0.8,\n",
    "    streamer=streamer,\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b413ea-ae89-4185-b717-2ae1be65d40a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# プロンプトの準備\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT = \"参考情報を元に、ユーザーからの質問に簡潔に正確に答えてください。\\n\"\n",
    "text = \"参考情報：\\n{context}\\n\\nユーザからの質問：\\n{question}\"\n",
    "template = \"{bos_token}{system}{prompt}\".format(\n",
    "    bos_token=tokenizer.bos_token,\n",
    "    system=DEFAULT_SYSTEM_PROMPT,\n",
    "    prompt=text,\n",
    ")\n",
    "\n",
    "rag_prompt_custom = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06adbc0-9ff0-45ba-b56f-f2d18fef8151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# チェーンの準備\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=rag_prompt_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dffc08-6f1a-49b4-8599-7b4799909f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###################################################\n",
    "# 生成\n",
    "#######################################################\n",
    "\n",
    "# まずはRAGなしでLLMに質問してみる\n",
    "\n",
    "# RAG なしの場合\n",
    "# 質問内容のみを入力として、文章生成\n",
    "inputs = template.format(context=\"\", question=question)\n",
    "start = time.time()\n",
    "output = llm(inputs)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"RAGなし\")\n",
    "print(f\"処理時間[s]: {elapsed_time:.2f}\")\n",
    "print(f\"出力内容：\\n{output}\")\n",
    "print(f\"トークン数: {llm.get_num_tokens(output)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a3cb9-c58b-417d-bc6f-605149190fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# RAG ありの場合\n",
    "start = time.time()\n",
    "# ベクトル検索結果の上位3件と質問内容を入力として文章生成\n",
    "inputs = {\"input_documents\": docs, \"question\": question}\n",
    "output = chain.run(inputs)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"RAGあり\")\n",
    "print(f\"処理時間[s]: {elapsed_time:.2f}\")\n",
    "print(f\"出力内容：\\n{output}\")\n",
    "print(f\"トークン数: {llm.get_num_tokens(output)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4d593-754f-4800-a5c1-d90363397b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# メモリを解放\n",
    "\n",
    "del model, tokenizer, pipe, llm, chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b88dea8-a71b-4437-860c-714bedd5abda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4a121-33aa-4b16-936c-d4f6e960aab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b033a8f-7b97-45d9-9acb-e808c8628346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
